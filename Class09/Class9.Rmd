---
title: "class09"
author: "Andres Rivero"
date: "10/27/2021"
output: pdf_document
---

```{r}
fna.data <- "WisconsinCancer.csv"

```


```{r}
wisc.df <- read.csv(fna.data, row.names=1)
head(wisc.df)
```

```{r}
wisc.data <- wisc.df[,-1]
diagnosis <- factor(wisc.df$diagnosis, levels = c("B", "M"))
print(diagnosis)
```
**Q1: How many observations are in this dataset?**
```{r}
dim(wisc.data)

```
It looks like there is 569 different observations.


**Q2: How many of the observations have a malignant diagnosis?**

```{r}
table(diagnosis)
```
There is 212 malignant observations

**Q3: How many variables/features in the data are suffixed with _mean?**
```{r}
length(grep("_mean", colnames(wisc.data)))
```
10 columns have the term "_mean" in them



Next: PCA

Check column means and standard deviations
```{r}
colMeans(wisc.data)
apply(wisc.data,2,sd)

wisc.pr <- prcomp(wisc.data, scale. = TRUE)

```
```{r}
summary(wisc.pr)
```

**Q4: From your results, what proportion of the original variance is captured by the first principal components (PC1)?**
44.27%

**Q5: How many principal components (PCs) are required to describe at least 70% of the original variance in the data?**
3

**Q6: How many principal components (PCs) are required to describe at least 90% of the original variance in the data?**
7

```{r}
biplot(wisc.pr)
```
**Q7: What stands out to you about this plot? Is it easy or difficult to understand? Why?**

Can't understand anything on the plot, impossible to read

```{r}
plot( wisc.pr$x , col = diagnosis , 
     xlab = "PC1", ylab = "PC2")
```
**Q8: Generate a similar plot for principal components 1 and 3. What do you notice about these plots?**

```{r}
  plot( wisc.pr$x[, c(1,3)] , col = diagnosis , 
     xlab = "PC1", ylab = "PC3")
```
There seems to be two different cluster of cells, red dots(or malignant) and black dots (or benign)


**Creating ggplot for our data**

```{r}
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis
```

```{r}
library(ggplot2)
ggplot(df) + aes(PC1, PC2, col=diagnosis) + 
  geom_point()
```
**Calculating the variance now**

```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```
```{r}
pve <- pr.var/(sum(pr.var))
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```
**Q9: For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?**

```{r}
wisc.pr$rotation["concave.points_mean",1]

```

**Q10: What is the minimum number of principal components required to explain 80% of the variance of the data?**

```{r}
summary(wisc.pr)
```
**We need The first 5 PCs to get to at least 80%**




**Q11: Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?**
*Hierarchical clustering*

```{r}
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist)
plot(wisc.hclust) +
abline(h=19, col="red", lty=2)
```

Height 19 gives us 4 clusters.



```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, h=19)
table(wisc.hclust.clusters, diagnosis)
```



**Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?**


```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, h=10)
table(wisc.hclust.clusters, diagnosis)
```
```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, h=20)
table(wisc.hclust.clusters, diagnosis)
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, h=24)
table(wisc.hclust.clusters, diagnosis)
```

It seems that height 19-20 gives us the best clusters.
 
**Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.**


```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:4]), method="ward.D2")
plot(wisc.pr.hclust)
abline(h=80, col="red")
```

**Q15: How well does the newly created model with four clusters separate out the two diagnoses?**

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

Comparing it to the expert M and B vector

```{r}
table(diagnosis)
```


We can do a cross-table by giving the table() function two inputs. (Called confusion table)

```{r}
table(grps, diagnosis)
```


**Accuracy**, essentially how many did we get correct?

```{r}
(165+351)/nrow(wisc.data)
```
**Q17: Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?**

**Sensitivity**
```{r}
165/(165+47)
```

**Specificity**
```{r}
351/(351+47)
```


```{r}
url <- "new_samples.csv"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], labels=c(1,2), col="white")
```

**Q18. Which of these new patients should we prioritize for follow up based on your results?**
Patient number 2


